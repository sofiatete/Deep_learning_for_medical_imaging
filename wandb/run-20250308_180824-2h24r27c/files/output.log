[34m[1mwandb[0m: logging graph, to disable use `wandb.watch(log_graph=False)`
watch!
checkpoint!
GPU available: True (mps), used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/opt/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.
trainer!

  | Name  | Type          | Params | Mode
------------------------------------------------
0 | model | SimpleConvNet | 36.0 K | train
------------------------------------------------
36.0 K    Trainable params
0         Non-trainable params
36.0 K    Total params
0.144     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
Sanity Checking DataLoader 0:   0%|                                                                             | 0/2 [00:00<?, ?it/s]loss!
/opt/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                  | 1/2 [00:02<00:02,  0.34it/s]loss!
Epoch 0:   0%|                                                                                                 | 0/54 [00:00<?, ?it/s]End GaussianBlur
/opt/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:   2%|â–ˆâ–                                                                           | 1/54 [00:03<02:42,  0.33it/s, v_num=r27c]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:   4%|â–ˆâ–ˆâ–Š                                                                          | 2/54 [00:04<01:45,  0.49it/s, v_num=r27c]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:   6%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                        | 3/54 [00:04<01:24,  0.61it/s, v_num=r27c]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                       | 4/54 [00:05<01:13,  0.68it/s, v_num=r27c]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                     | 5/54 [00:06<01:06,  0.74it/s, v_num=r27c]

Detected KeyboardInterrupt, attempting graceful shutdown ...
