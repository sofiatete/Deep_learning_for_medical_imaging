[34m[1mwandb[0m: logging graph, to disable use `wandb.watch(log_graph=False)`
watch!
checkpoint!
GPU available: True (mps), used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/opt/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.
trainer!

  | Name  | Type     | Params | Mode
-------------------------------------------
0 | model | ResNet50 | 24.6 M | train
-------------------------------------------
16.1 M    Trainable params
8.5 M     Non-trainable params
24.6 M    Total params
98.492    Total estimated model params size (MB)
161       Modules in train mode
0         Modules in eval mode
Sanity Checking DataLoader 0:   0%|                                                                             | 0/2 [00:00<?, ?it/s]loss!
/opt/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Sanity Checking DataLoader 0:  50%|██████████████████████████████████▌                                  | 1/2 [00:08<00:08,  0.12it/s]loss!
Epoch 0:   0%|                                                                                                 | 0/54 [00:00<?, ?it/s]End GaussianBlur
/opt/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:   2%|█▍                                                                           | 1/54 [00:09<08:09,  0.11it/s, v_num=11qy]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:   4%|██▊                                                                          | 2/54 [00:16<07:16,  0.12it/s, v_num=11qy]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:   6%|████▎                                                                        | 3/54 [00:24<06:58,  0.12it/s, v_num=11qy]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:   7%|█████▋                                                                       | 4/54 [00:32<06:47,  0.12it/s, v_num=11qy]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:   9%|███████▏                                                                     | 5/54 [00:40<06:41,  0.12it/s, v_num=11qy]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:  11%|████████▌                                                                    | 6/54 [00:49<06:33,  0.12it/s, v_num=11qy]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:  13%|█████████▉                                                                   | 7/54 [00:57<06:27,  0.12it/s, v_num=11qy]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:  15%|███████████▍                                                                 | 8/54 [01:06<06:20,  0.12it/s, v_num=11qy]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:  17%|████████████▊                                                                | 9/54 [01:15<06:16,  0.12it/s, v_num=11qy]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:  19%|██████████████                                                              | 10/54 [01:24<06:12,  0.12it/s, v_num=11qy]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:  20%|███████████████▍                                                            | 11/54 [01:35<06:11,  0.12it/s, v_num=11qy]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!
loss!
Epoch 0:  22%|████████████████▉                                                           | 12/54 [01:47<06:16,  0.11it/s, v_num=11qy]End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
End GaussianBlur
training stepppp!

Detected KeyboardInterrupt, attempting graceful shutdown ...
